 <!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

		<title>Introduction to AI - Statistics and AI</title>

		<!--<link rel="stylesheet" href="dist/reset.css">-->
		<link rel="stylesheet" href="../../reveal.js/dist/reveal.css">
		<link rel="stylesheet" href="../../reveal.js/dist/theme/moon.css">

		<!-- Theme used for syntax highlighted code -->
		<!--<link rel="stylesheet" href="plugin/highlight/monokai.css">-->
		
        <!-- Custom CSS file		 -->
        <link rel="stylesheet" href="../../ft.css">
    
        <script src="../../jquery-3.6.0.min.js"></script>    
        <script type="text/javascript" src="../../ft.js"></script>
		
	</head>
	<body>
<div class="reveal">
    <div class="slides">
    
<section>
            <h1> Statistics and AI </h1>
            <p> Lecture: Introduction to Artificial Intelligence </p>
            <p> Part 8 </p>
</section>
        
<section>
            <h2> Learning objectives </h2>
            <div style="text-align: left;">
             <p>In this section you will learn...</p>
             <ul>
                 <li>...What data are</li>
                 <li>...What distributions are</li>
                 <li>...Important statistic methods</li>
                 <li>...approaches to improve data for analysis</li>
             </ul>
            </div>
</section>

<section>
            <h2> Credits </h2>
            <p>Contents are inspired and adopted from Leland Wilkinson, University of Illinois, Chiacago and his Lecture Notes on Data Analysis, Statistics, and Machine Learning.</p>
            <a href="https://www.cs.uic.edu/~wilkinson/"> Leland Wilkinson home page </a>
</section>
    
<section data-markdown
         data-separator="^\n\s*---\n$" 
         data-separator-vertical="^\n\s*--\n$">
<textarea data-template>
## Data
* Data may have different *forms*
	* Set, List, Table, etc.
	* These can be used in data analysis
	* But they are **not suitable** for statistics

--

<p class="important"> Statistics operate on <b>variables</b>, not data! </p>
<ul>
    <li> Variable: <em>function</em> mapping data objects to <em>values</em> </li>
    <li> Random variable: <em>values</em> are associated to a <em>probability</em> </li>
</ul>

--

### Data sets
Generally: do **not** allow duplicates!

--

### Flat files
* Flat file tables with n rows and p columns
* Rows are independent of each other
* Row corresponds to a observation, Column to variable
* Common: Comma-separated values (CSV), Excel

<p class="example"> <code>John,Doe,12 may st.,Riverside, NJ, 08075</code></p>

--

### Relational database

<div style="text-align: left;">

**Relation variable:** A function relating values to objects
* A relation variable has a domain
* Domain: Set of scalar values of one type (integers, strings, etc.)

**Table:** A collection of relations
* Each Row is a tuple
* Each Column is an attribute specifying a domain

**SQL:** A language for manipulating tables
</div>

--

<p class="important"> Relational databases are <b>not</b> suitable for statistics </p>

Statistic methods require ordering of values:
* Tuples in tables are unorderd
* Colums are unordered
    * Unsuitable for time series statistics
* Sample may contain duplicates
    * Not allows in relational databases
    
<p class="note"> Hacks exist </p>

--

### Distributed File systems

**Problem:**
* Classic databases cannot handle huge files
* Distributed databases can but computational complexity is increasing
* Statistical calculations on single files do not scale

**MapReduce / Hadoop:**

<div style="text-align: left;">

* Data slicing allows for parallel statistical calculations
    * Good for data regression

</div>

--

### MapReduce

<!-- .slide: data-background=" #a3c1ad" -->
![MapReduce2.svg](figures/MapReduce2.svg)

<div style="text-align: right;">

Soruce: Wikipedia

</div>

--

### Graph databases
* A graph `$ G = (V,E) $` pair of sets
    * `$V$` set of vertices, 
	* `$E$` set of edges
* Graph databases store nodes indexed by edges
	* Each node has set of properties
	* Statistical metrics exists
        * Diameter, Centrality, Giant
	* Scalable: efficient for traversals

--

### Streaming (time series) databases
* Data objects ordered in time
* Data objects enter "real-time"
	* Environmental sensor data
	* Stock market data
* Data retrievable with short delay
* Statistical methods must be able to handle data streams
	* running windows, moving averages
	* Update methods

<p class="example"> InfluxDB </p>

--

### Symmetric matrices

`$ \textbf{S} $` is a symmetric matrix `$ (s_{ij} = s_{ji}) $`

* Types of data that comprise *symmetric* matrices
	* (Dis)similarities
	* Distances
	* Correlations
* Analytical methods using input as *symmatric* matrix
	* Principal components
	* Hierarchical clustering
	* Multidimensional scaling (MDS)


--

### Exercise: Symmetric Matrices in R
<!-- .slide: data-background=" aquamarine" -->
<div class="exercise"> 

Please create a symmetric `$ 10 \times 10 $` matrix in R. Consider the R functions <code>lower.tri()</code> and <code>upper.tri()</code>. Fill the matrix with a sequence of numbers as given in the `$ 3 \times 3 $` matrix below.

`$$
\begin{bmatrix}
0 & 1 & 2 \\
1 & 0 & 3 \\
2 & 3 & 0 
\end{bmatrix}
$$`

Time: 15 Minutes

</div>

---

## Probability distributions

--

### Probability functions

<div style="text-align: left;">

**A probability function** is a non-negative function with an area (or mass) of 1.

**Distributions** are families of probability functions
* Most statistical methods depend of distributions

**Most popular:** The Normal (Gaussian) distribution
* Central limit theoreme

</div>

<p class="note"> Random variables based on real data are rarely normally distributed, but sums or means of random variables tend to be. <br> &rarr; Normal assumption is OK, if we believe in that. </p>

--

### Random variables

A **random variable** is a mapping from a set of objects to a set of values:

`$$ X \equiv f : O \rightarrow V $$`

**Values** are associated with probabilities:   
* **Discrete random variable:** associates a *value* with a probability.
* **Contionuous random variable:** associates an *interval* with a probability.    

**Probability distribution**: *Mathematical function* describing the *possible values* of a random variable and their associated probabilities.

--

### Expectations of random variables
* The **expected value** of a random variable is the *weighted average* of the values of that variable
    * Weights are the probabilities(!)
* Allows computing of the *maximum likelihood estimates* of the mean

<p class="note"> Notation for expected value: $$ E(X) $$ </p>

--

### Definitions

`$$ \begin{aligned} 
E(c) &amp= c \\
E(cX) &amp= cE(X) \\
E(c+X) &amp= c + E(X) \\
E(X+Y) &amp= E(X) + E(Y) \\
E(XY) &amp= E(X) E(Y) \textrm{ If X, Y indepedent} \\
VAR(X) &amp= E(X^2) - E(X)^2 \\
VAR(cX) &amp= c^2VAR(X) \\
VAR(c + X) &amp= VAR(X) \\
VAR(X+Y) &amp= VAR(X) + VAR(Y) \textrm{ If X, Y indepedent} \\
COV(X,Y) &amp= E(XY) - E(X)E(Y) \\
VAR(X+Y) &amp= VAR(X) + VAR(Y) + 2COV(X,Y) \\
VAR(X-Y) &amp= VAR(X) + VAR(Y) - 2COV(X,Y) 
\end{aligned}$$`

--

### Variance and Standard Deviation and Covariance

**Variance** of random variable `$ X $`, `$ VAR(X) $`, measures *dispersion* of values around `$ E(X) $`.

`$$ VAR(X) = E((X-\mu)^2) $$`

**Standard Deviation:** Average distance from the mean

`$$ \sigma(X) = \sqrt{VAR(X)} $$`

<p class="note"> The <b>Covariance</b> measures if high values of one random variable relate more to high or low values of another. </p>

--

### The law of large numbers (LLN)
"The average of the results obtained from a large number of trials should approximate the expected value with increasing number of trials."

![Lawoflargenumbers.svg](figures/Lawoflargenumbers.svg)


--

### Exercise: LLN
<!-- .slide: data-background=" aquamarine" -->
<div class="exercise"> 

To experience the LNN we can to a Monte Carlo (MC) experiment in R. For this, consider a box that holds `$ 10 $` tickets. Three of them are labled with the letter "A"; the rest are labled "B". To execute a repeated random process (executing trials) R provides the function <code>sample()</code>.

1. Execute the MC experiment in R for 20 times. Set the <code>replace</code> parameter of <code>sample()</code> to <code>TRUE</code>.
2. Compute the proportion of times a A-ticket or B-ticket as been selected. You may use the <code>prop.table()</code> function of R.
3. Execute the MC experiment in R for 10000 times and compute the proportion.
4. Compare the results of 2. and 3.

Time: 15 Minutes.

</div>

--

### Exercise: Expected Value
<!-- .slide: data-background=" aquamarine" -->
<div class="exercise"> 

Imagine that you are about to play the following game: you will flip a fair coin twice.
* If you get Tails both times, you lose a dollar.
* If you get exactly one Head, nothing happens.
* If you get Heads both times, you win two dollars.

Let `$ W $` be the number of dollars you will win. `$ W $` is a clearly a random variable: it’s a number whose value - either -1, 0, or 2 — depends on the outcome of the random process of flipping the fair coin twice. What is the expected value of W?

</div>

--

<!-- .slide: data-background=" aquamarine" -->
<div class="exercise"> 

### Step-by-step
1. What are the possible outcomes of the trial and what are they meaning for `$ W $`?
2. What are the probabilities of W takes the values -1, 0, or 2?
3. Compute the expected value, manually.
4. Execute a MC experiment using the <code>sample()</code> function. Provide a vector `$\textbf{w}$` of possible values for `$ W $` and a vector `$\textbf{pw}$` containing the respective probabilities (see 2.). Assign `$\textbf{pw}$` to the parameter <code>prob</code> of <code>sample()</code>.

Time: 20 Minutes.

</div>

--

<!-- .slide: data-background=" aquamarine" -->
<div class="exercise"> 

### Probability Distribution
The linked tutorial introduces several important probablity distributions. As an exercise work through the exercise.

[Probability Distributions](http://www.r-tutor.com/elementary-statistics/probability-distributions)

Time: 45 Minutes.

</div>

---

## Summarizing Data

--

### Removing irrelevant detail    
* Summarising batches of data in a few numbers    
* Summarising variables through their distributions    
* Best: preserve important information    
* All summaries lose information 

--

### Statistical measures
* **Location**    
	* Popular: mean, median 
	* Others: weighted mean, trimmed mean,    ...    
* **Spread**    
	* Popular: standard deviation (sd), range    
	* Others: Interquartile range, Median Absolute Deviation,    ...    
* **Shape**    
	* Skewness 
	* Kurtosis

--

### Location
**Mean**
`$$ mean = \sum_{i=1}^n \frac{(x_i)}{n} $$`

* Mean is the value whose sum of *squared deviations to `$ x_i $` is smallest*
* Good if batch is symmetrically distributed
* Not good in case of outliers or severe skewness of the distribution

--

**Median**

Median =  middle value of ordered list of `$ x_i (i = 1, ..., n) $`
* If `$ n $` is even, any value between the two middle values is a median (often: average of the two)
* Median is value whose sum of *absolute deviations is smallest*
* Median splits the batch
* Robust against outliers   

--

### Spread
**Standard deviation (sd)**
`$$ \sigma(X) =\sqrt{(VAR(X))} $$`
It means Literally:
`$$ \sqrt{(mean(square(deviation(mean))))} $$`
* Designed for symmetric distributions (Normal distribution)
* Not robust (against outliers) 
	* Squaring large errors

--

### Shape
**Skewness:** Measures positive or negative asymmetry
* Think of long tail as arrow -> if its right: positive
* Not robust

<div style="background-color: #a3c1ad;">

![Skewness.svg](figures/Skewness.svg)
<p style="text-align: right;"> Wikipedia </p>

</div>

--

**Kurtosis:** Measures peaked of flat shape
* Not robust
* Gernally:
    * Small Kurtosis: Homogeneous spreading of events, 
    * Large Kurtosis: Spreading results from extreme but rare events.

![kurtosis4.png](figures/kurtosis4.png)

<p style="text-align: right;"> www.statext.com </p>


--

<!-- .slide: data-background=" aquamarine" -->
<div class="exercise"> 

### Data Summarising
Load a data set of your choice, e. g. built-in data set faithful and compute:
* mean
* median
* variance
* standad deviation
* covariance
* Interquartile range

Time: 20 Minutes.

</div>


---

## Smoothing
* Discovering patterns in data
* Patterns are described by smoothing functions
	* Kernel smoothing
	* Polynomial smoothing

--

### Scatter plot

![scatter.png](figures/scatter.png)

<p style="text-align: right;"> Wilkinson </p>

--

### Smoothing function

![scatter_smoothed.png](figures/scatter_smoothed.png)

<p style="text-align: right;"> Wilkinson </p>

--

### Kernel smoothing
* Uses basic statistical measures
	* mean, median, mode
* Adjacent data points are aggregated
	* k-nearest neighbor (KNN)
	* fixed distance

--

### Kernel smoothers

![kernel_smoothers.png](figures/kernel_smoothers.png)

--

### k-nearest-neighbors

![scatter_knn.png](figures/scatter_knn.png)

--

### Fixed distance

![scatter_fixed.png](figures/scatter_fixed.png)

--

### Polynomial smoothing
* Uses a polynomial function
    * Linear
    * Higher-order

--

### Linear regression

<!-- [Video](https://www.youtube.com/watch?v=osPwkFkYvNc) -->

Measuring the influence of one random variables `$ X $` on another random variable `$ Y $`: 

`$$ X \rightarrow Y:= X \textrm{ affects/influcences } Y $$`

`$ X $` is called **independent** variable, `$ Y $` **dependent** variable

<p class="important"> A plausible assumption / evidence of existing influence is needed! </p>

**Goal:** Finding a function that approximates the relation in the best way

--

### Linear regression: Linear function

<div style="background-color: #a3c1ad;">


<img src="figures/linear_regression.svg" 
     height="500" />

</div>

<p class="note"> Shows covariance: Tendence that high values of one random variable relate to high values the other. </p>

--

### Spline regression

Higher-order function expressing relation between variables.

![spline.png](figures/spline.png)

--

<!-- .slide: data-background=" aquamarine" -->
<div class="exercise"> 

### Linear regression

1. Load the *cars* data set using the <code>data()</code> function.

2. Plot car speeds on the y-axis and stopping distances on the x-axis. What kind of pattern is present?

3. Using the <code>lm()</code> function to fit a linear model to the data with the stopping distance as the response variable. Plot the line of best fit.

4. Use <code>summary()</code> to obtain parameter estimates and model details. Is the slope significantly different than zero? How much of the variance can be explained by car speed?

5. Use the <code>plot()</code> command on the linear model to obtain the four plots of residuals. The residuals are the difference between your observed data and your predicted values.

Time 30 Minutes.

</div>

---

## Time series and spacial statistics
* Time series: Random processes over *time*
* Spacial statistics: Random processes over *space*
* Both involve similar mathematical models

<p class="note"> Events at time/space point not necessarily independent: Smoothing difficult. </p>

--

### Stochastic processes
* Up to now: Independent, identically distributed (i.i.d.) random variables.
	* Two variables take same value with same probability
	* Variables are **not mutually** influencing
	* No ordering of random variables
	* Values are systematic effects + random error

--

### Time / Space Assumptions:
* Random variables are ordered across time or space
* Random variables are equally spaced (fixed delta)

--

### Autoregression (AR) / Autoregressive behaviour 
Each observation at a given time is a function of the *previous* plus random error

**Questions:** 
* How are the present observations influenced by the past observations? 
* How are local observations influenced by observations at neighboring locations?
* How many and which periods of the past / surrounding locations are relevant?

--

### First-order autoregression AR(1)
Observations at time `$ t $` are only influenced by observations at time `$t_{-1}$`.

* Correlate a series of random variables with itself shifted backwards by one time step.
* Correlate the shifted series with itself shifted backward by one time step
* And so on...

`$$ x_t = \mu + \phi x_{t-1} + \epsilon_t $$`

--

### Autoregression function plot

![autocorrelation.png](figures/autocorrelation.png)

<p style="text-align: right;"> Wilkinson </p>


--

### Moving average process
* Using the moving average of the past periods
* Observations at a given time is a function of the *previous error* plus random error

`$$ x_t = \mu + \theta_{\epsilon_{t-1}} + \epsilon_t $$`

--

### Autoregression function plot (Moving averages)

![Moving_averages.png](figures/Moving_averages.png)

<p style="text-align: right;"> Wilkinson </p>

--

### Generalisation: ARMA / ARIMA processes
Combination of both
`$$ x_t = \alpha + \beta x_t + \sum_{i=1}^p{\phi_i x_{t-1}} + \sum_{j=1}^q{\theta_j \epsilon_{t-j}} + \epsilon_t $$`
Not further discussed in this course

--

<!-- .slide: data-background=" aquamarine" -->
<div class="exercise"> 

### Autoregression 

Currently Missing. But there is the <code> acf() </code> function in R which provides autocorrelation function plots. Be creative ;-)

</div>

---

## Data reduction

--

### Reducing
A large number of variables is reduced to a smaller number of variables

* **Approaches:**
    * **Principal components (PC)**
    * Multidimensional scaling (MDS)
    * Manifold learning
    * Random projection

--

### Principal Component Analysis (PCA)

Dimension reduction by *orthogonal weighted linear combinations*

Typically a data set has matrix structure:

E. g. for `$ n $` objects (cars, cells, ...) `$ p $` features are measured. Gives `$ n $` points in the `$ p $`-dimensional space and can be described as `$ n \times p $` matrix.

<p class="important"> However, comparing or grouping n points by p dimensions is tidy! </p>

--

### PCA: General Idea

Extract the highly correlated dimensions into single ones such that the number of dimensions can be reduced with minimal loss of information.

<div class="example">

Often multiple features describe the same aspect of an object.
* Car: 
    * Speed and engine power &#8594; performance 
    * Length and weight &#8594; size
    * Seats and number of doors &#8594; capacity 

</div>

--

### Basics
**Eigenvector and Eigenvalue:** 

`$$ \textbf{S v} = \lambda \textbf{v} $$`

**Covariance Matrix:**

Comparision of two random variables regarding if high values of one variable relate to low values of the other variable.

`$$ COV(X_i,X_j) $$` 

**Matrix Transpose (Notation):** 

`$$ \textbf{X}^T or \textbf{X}^{-1}  $$`

--

### Principal Procedure

Determine vectors for each feature (dimension) describing the value best and being orthogonal to each other (least correlation)

1. Standardising the range of Contionuous variables
    * avoid bias resulting from large differences of ranges of variables
    * retrieve standardised data set
2.  Covariance matrix computation
    * Detect the relationsship between variables of the input data
    
`$$
\begin{bmatrix}
COV(X,X) & COV(X,Y) & COV(X,Z) \\
COV(Y,X) & COV(Y,Y) & COV(Y,Z) \\
COV(Y,Z) & COV(Y,Z) & COV(Y,Z) 
\end{bmatrix}
$$`

--

3. Identifying the PCs
    * Compute Eigenvalue and Eigenvector of the COV-Matrix
    
4. Selecting most relevant PCs (Feature Vector creation)
    * E. g. Krüger-Kriterium `$ \lambda > 1 $`
    
5. Transponing data to new axis
    `$$ NewData = FeatureVector^T \times StandardisedData^T $$`

--

### Exercise
<!-- .slide: data-background=" aquamarine" -->
<div class="exercise"> 

<p> Read the following articles and retrace the procedure: </p>
<ul>
 <li> <a href="https://builtin.com/data-science/step-step-explanation-principal-component-analysis"> 5 steps of PCA </a> </li>
 <li> <a href="https://tgmstat.wordpress.com/2013/11/21/introduction-to-principal-component-analysis-pca/"> Introduction to the PCA </a> </li>
 <li> <a href="https://setosa.io/ev/principal-component-analysis/"> PCA visually explained </a> </li>
</ul>

</div>

---

## Anomalies
* Literally: Lack of law
* Single data points that do not fit to the big picture

--

### Best-known: Outliers

"An outlier is an observation which deviates so much from the other observations as to arouse suspicions that it was generated by a different mechanism” (Hawkins, 1980)

* Presumes a distribution with tails
* Identifying outliers is tidy

--

### Other anomalies
* Coding errors in data
* Misspellings
* Singular events

--

### Anomalies may bias statistical estimates
Don't worry about outliers but their influence!

![anomalies1.png](figures/anomalies1.png)

<p class="important"> Do <b>not</b> drop outliers before fitting and unless you know why they are outliers. There are alternatives such as robust methods, trimming </p>

--

### Why outliers are interesting
* Improve effectiveness of research
	* Explicetly evaluate outliers instead of standard results
* Outliers may lead to a better model
	* No outlier without a model!
	* Examining outliers may help to improve the model

--

### Tests of outliers
* Popular tests evaluate the distance of data values from the center. Such as
	* Grubbs
		* Iteratively removes outliers 1-by-1.
	* Tukey
		* Interquartile range: `$ Q_3 - Q_1 $`
		* Rule of thumb: Outlier if value is outside `$ 1.5 IQR $`
		
`$$ value > Q_3 + 1.5(IQR) \text{ or } value < Q_1 - 1.5(IQR) $$`
	
<p class="note"> Both require Normal Distribution </p>

--

![outliers.png](figures/outliers.png)

<p style="text-align: right;"> Wilkinson </p>

* Left has an outlier but not right?
    * Both samples have same mean and SD
    * &#8594; Problem boils down to gaps not to distance from centre

--

### Graphical methods

--

## Box plot

![boxplot.png](figures/boxplot.png)

<p style="text-align: right;"> Wilkinson </p>

--

## Probability plot

![probability_plot.png](figures/probability_plot.png)

<p style="text-align: right;"> Wilkinson </p>

<p class="note"> Necessary to know the distribution </p>

--

## Transformations

![transformations.png](figures/transformations.png)

<p style="text-align: right;"> Wilkinson </p>

In particular skewed batches can profit from transformations

--

## Spikes

![spikes.png](figures/spikes.png)

* Use dot plots, check for stacks

<p style="text-align: right;"> Zuur et al. </p>


--

## Multivariate Outliers

![mahalanobis.png](figures/mahalanobis.png)

Mahalanobis distance

--

### Exercise
<!-- .slide: data-background=" aquamarine" -->
<div class="exercise"> 

<p> Compute the Mahalanobis distance </p>

[Exercise Mahalanobis Distance](https://www.r-bloggers.com/2021/08/how-to-calculate-mahalanobis-distance-in-r/)

</div>


---

## Hypothesis testing

--

As a model of statistical inference, hypothesis testing is a method to check if the available data prove or disprove a previously stated hypothesis

--

### 5 steps of hypothesis testing

1. Stating the hypotheses
2. Collecting the data suitable to test the hypothesis
3. Statistical testing
4. Checking if hypothesis holds or is rejected
5. Presentation of the results

--

### Stating the hypotheses

Required: Null-hypothesis H<sub>0</sub> and the alternate hypothesis H<sub>a</sub>.

H<sub>a</sub>: Assumes a relationship between the considerd random variables.
H<sub>0</sub>: Assumes **no relationship** between the random variables.

--

<div class="example">

### Vitamin C protects against cold

You want to know if the regular consumption of vitamin C protects against getting a cold. From your own observation you assume that people that consume vitamin C preparates have less sick days as others. Hence:

H<sub>0</sub>: People consumed regularly vitamin C have same sick days than others.

H<sub>a</sub>: People consumed regularly vitamin C have less sick days than others. 

</div>

--

### Collecting data

Very important: Collect and sampling representative data:

* Equal proportion in variables
* Sufficient size of the sample
* Covering different external parameters
* Locational scope (region, worldwide)

--

<div class="example">

### Vitamin C protects against cold

* Equal population of consumers and non-consumers
* Equal proportion of male, female 
* Variety of socio-economic classes
* Variety of age classes
* Variety of climate zones

</div>

--

### Performing the statistical test

Statistical tests usually perform an comparision between **within-group variance** versus **between-group-variance**.

Hence: Grouping of data is necessary
* Male / female
* Adult / children
* Users / non-users

--

### within-group-variance
How spread the data within a category

### between-group-variance
How different are groups from each other?

--

### p-value (probability value)

Describes the likelihood that a particular set of observations supports H<sub>0</sub>.

A small p-value means rejecting H<sub>0</sub>.

--

The p-value says how often a test statistic (e. g. t-test) would be as extreme or more extreme as the one calculated using the collected data if H<sub>0</sub> would be true.

<div class="example">
	p-value of 0.05 means that in 5% of the time a statistic test would be at least as extreme as the one found if H<sub>0</sub> was true.
</div>

--

### p-value and statistical tests

p-values are related to the statistical test used:

* Different statistical tests have different assumptions and generate different test statistics:
	* Test must fit to collected data and must match the effect/relationship to be tested
* The number of **independent variables** included changes how large/small the test statistic needs to be to generate the same p-value

--

### p-values and statistical significance

A result is statistically significant if it is unlikely to be explained by chance or random factors

--

<!-- .slide: data-background=" aquamarine" -->
### Question

How does this statement relate to the p-value?

--

### Choosing statistical tests

Choice is based on *type of data*:

**Quantitative data:** (describing amounts)
* Discrete: integers (e.g. number of students)
* Continuous: ratios (e.g. temperature)

**Qualitative data:** (describing groupings)
* Binary: boolean (e.g. true/false)
* Nominal: unordered groups (e.g. Colours, Brands)
* Ordinal: ordered groups (e.g. adults/children, consumers/non-consumers)

--

**Independent variables**
* usually *manipulated* within experiment

**Dependent variables**
* usually *measured* within experiment

**Control variables**
* Held constant during the experiment

--

![choosing_stat_test.svg](figures/choosing_stat_test.svg)

--

<div class="example">

### Vitamin C protects against cold
	
Based on the data collected, a one-tailed t-test is being performed. This results in:
* An estimate of the difference in sick days between the two groups
* a **p-value** showing how likely it is to see this difference if the null hypothesis of no difference is true.
	
The difference in sick days, e. g, 4,6 days for vitamin c consuments and 5,4 days for non-consuments with an estimate of the true difference of 2.4 days. The p-value might be 0.07.
	
</div>

--

### Checking if hypothesis holds or is rejected

the resulting p-value is 0.07, hence > 0.05. In that case the null-hypothesis H<sub>0</sub> holds. Apparently there is no difference between the two groups (the difference in the data could be by chance).

--

### Presenting the results

* Hypothesis tesing does is not a proof
* It merely shows that our data supports the alternate hypothesis or not
* Nothing more.

--

<!-- .slide: data-background=" aquamarine" -->
### Excercise

TBD

---

<!--
[5steps](https://www.scribbr.com/statistics/hypothesis-testing/)
[tests](https://www.scribbr.com/statistics/statistical-tests/)
[testingR](https://www.statology.org/hypothesis-testing-in-r/)
[testinginr8](https://www.andrew.cmu.edu/user/achoulde/94842/lectures/lecture07/lecture07-94842.html)
[introtohypotestin](https://data-flair.training/blogs/hypothesis-testing-in-r/)
[T und mu test](https://techvidvan.com/tutorials/hypothesis-testing-in-r/)
[r tutorial](http://www.r-tutor.com/elementary-statistics/hypothesis-testing)
[Examples hypo testing](https://rstatisticsblog.com/data-science-in-action/data-preprocessing/hypothesis-testing-in-r-with-examples-interpretations/)
-->

## Not topic this time
* Comparing and Grouping of random variables
* Inference
* Machine Learning
* Visualisation / Exploring
</textarea>
</section>
    </div>
</div>
		
		<script src="../../reveal.js/dist/reveal.js"></script>
		<script src="../../reveal.js/plugin/notes/notes.js"></script>
		<script src="../../reveal.js/plugin/markdown/markdown.js"></script>
		<script src="../../reveal.js/plugin/highlight/highlight.js"></script>
<!-- 		<script src="reveal.js-plugins/animate/plugin.js"></script> -->
<!-- 		<script src="reveal.js-plugins/animate/svg.min.js"></script>--> -->
<!--         <script src="reveal.js/plugins/audio-slideshow/plugin.js"></script> -->
<!--         <script src="reveal.js/plugins/audio-slideshow/RecordRTC.js"></script> -->
<!--         <script src="reveal.js/plugins/audio-slideshow/recorder.js"></script> -->
        <script src="../../reveal.js/plugin/math/math.js"></script>
<!--        <script src="reveal.js/plugins/menu/menu.js"></script>-->
		<script>
// 			More info about initialization & config:
// 			- https://revealjs.com/initialization/
// 			- https://revealjs.com/config/
			Reveal.initialize({
				hash: false,
				height: 900,
				width: 1200,
				controls: true,
				progress: true,
				history: true,
				center: true,
				mouseWheel: true,
				previewLinks: false,
				slideNumber: true,
// 				autoSlide: 5000,
// 				animate: {
// 					autoplay: false
// 				},

				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, /*RevealAnimate,*/ RevealMath ]
			});
		</script>
	</body>
</html>
